{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Решаю задачу бинарной классификации временных рядов.\n",
    "Предсказываю бар определенного типа:\n",
    "- для лонга: верхняя тень в несколько раз больше чем нижняя\n",
    "- для шорта: нижняя тень в несколько раз больше чем верхняя\n",
    "\n",
    "Классы не сбалансированны, целевой класс не более 10-15% в выборке в зависимости от настройки\n",
    "\n",
    "Для моих целей задачи классификации смотрю на метрики:\n",
    "- Precision - точность, т.к. сколько в % от предсказаний класса 1 действительно правда. Хотелось бы увидитеть хотя бы 20% в этом месте я в нуле если соотношение доходность/риск как 4к1.\n",
    "- Recall - полнота, сколько % объектов класса 1 я нашел относительно всех объектов класса 1. Тут я на самом деле не закладываюсь, просто наблюдаю что бы были адекватные значения. Если всего объектов класс 1 на истории 4т, то 10% словить при высоких значениях Precision это тоже хорошо. А вот 1%, это уже маловато, это всего 40 сделок.\n",
    "- f1 использую как объединение предыдущих метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Загружаю исторические данные из паркет файлов.\n",
    "\n",
    "По умолчанию я использую часовик. Но тут в список или лучше в словарь могу загрузить сразу много файлов разных таймфреймов\n",
    "- 2min\n",
    "- 3min\n",
    "- 5min\n",
    "- 10min\n",
    "- 15min\n",
    "- 20min\n",
    "- 30min\n",
    "- 1H\n",
    "- 2H\n",
    "- 3H\n",
    "- 4H\n",
    "\n",
    "И в цикле в итоге искать где лучше всего алгоритм работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Исследование данных\n",
    "\n",
    "Проведение тестов на стационарность\n",
    "\n",
    "Задача получить стационарные временные ряды, отчистить их от трендов. Что бы тренировочные и тестовые части находились в одном пространстве признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Target Category Feature \n",
    "Создаю целевой признак\n",
    "\n",
    "Это фактически очередные гиперпараметры.\n",
    "\n",
    "Я могу задавать уровень риска в лог величинах - risk_level\n",
    "\n",
    "и коэффициент доходность/риск в виде множителя - risk_factor\n",
    "\n",
    "Т.е. текущий случай это:\n",
    "* risk_level = 0.0025\n",
    "* risk_factor = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_level = 0.0025\n",
    "profit_factor = 4\n",
    "profit_level = risk_level * profit_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "* Преобразую исходные данные\n",
    "* Получаю новые признаки. \n",
    "* Удаляю ненужные.\n",
    "* Обогощаю данные.\n",
    "\n",
    "* Объемы и сделки:\n",
    "Можно считать средний объем сделки. \n",
    "- AvrTrade = Volume / Trades\n",
    "- Объем в долларах, т.е. нормированный объем VolUSD = Volume * Close\n",
    "- Объем на единицу диапазона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "Обработка выбросов. Пробовать прорядить выборку удалением записей по методу:\n",
    "- 3х сигм\n",
    "- методу Тьюки\n",
    "- Isolation Forest\n",
    "- Local Outlier Factor\n",
    "- Minimun Covariance Determinant\n",
    "\n",
    "Но обработку надо делать уже после разделения выборки на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform TimeSeries to Dataset for Supervised Learning\n",
    "Тут определяется глубина последовательности данных которая будет использоваться для построения прогноза T.\n",
    "\n",
    "Т это так же гиперпараметр, его так же нужно будет искать по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 24 # данные за сутки беру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Различия между ML и DeepLearning\n",
    "Как я понимаю сейчас алгоритмы ML принимают на вход только вектор признаков для конкретного объекта датасета.\n",
    "Т.е. Close текущего бара, или Log_Return на текущем баре. Но каждый признак состоит из T этих признаков в прошлое.\n",
    "\n",
    "И получаетмя что это двумерный массив.\n",
    "\n",
    "Но для подачи данных в ML модели мне эту матрицу нужно развернуть наверное с помощью flatten в вектор.\n",
    "А вот в модели ANN я могу подавать матрицу размерностью T * D.\n",
    "\n",
    "Т.е. в функции трасформации и создания датасета из временного ряда должен быть аргумент для чего мы делаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Preperation\n",
    "Первое разделение данных на общую (тренировочную/валидационную) и тестовую.\n",
    "Тут разделение нужно произовить без перемешивания и стратификации.\n",
    "\n",
    "Это будет похоже на релаьную симуляцию работы. Когда общая левая часть это все доступные текущие данные. А левая это то что будет появляться в режиме реального времени. И на чем будет производиться тестирование модели, а фактически реальное использование модели для торговли.\n",
    "\n",
    "\n",
    "Но может я не прав и деление тут тоже надо производить случайным образом и со стратификацией. Теперь кажется что так тестирование будет более полным и равномерным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "Теперь левую общую часть надо разделить на тествоую и валидационную случайным образом и с учетом несбалансированности классов, применяя стратификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "Теперь наверное можно нормальзовать данные.\n",
    "Скалер обучаю только на X_train, а трансформирую все три матрицы X_test, X_valid, X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
