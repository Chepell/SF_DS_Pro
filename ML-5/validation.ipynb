{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы будем решать задачу классификации: \n",
    "\n",
    "классифицировать воду на пригодную  и не пригодную для питья на основе её химического состава.\n",
    "\n",
    "Скачать набор данных можно здесь. С подробным описанием датасета и столбцов таблицы ознакомьтесь в источнике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # для матричных вычислений\n",
    "import pandas as pd # для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt # для визуализации\n",
    "import seaborn as sns # для визуализации\n",
    " \n",
    "from sklearn import metrics # метрики\n",
    "from sklearn import model_selection # методы разделения и валидации\n",
    "from sklearn import linear_model # линейные модели\n",
    "from sklearn import tree # деревья решений\n",
    "plt.style.use('seaborn') # стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>4.668102</td>\n",
       "      <td>193.681735</td>\n",
       "      <td>47580.991603</td>\n",
       "      <td>7.166639</td>\n",
       "      <td>359.948574</td>\n",
       "      <td>526.424171</td>\n",
       "      <td>13.894419</td>\n",
       "      <td>66.687695</td>\n",
       "      <td>4.435821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>7.808856</td>\n",
       "      <td>193.553212</td>\n",
       "      <td>17329.802160</td>\n",
       "      <td>8.061362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392.449580</td>\n",
       "      <td>19.903225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.798243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>9.419510</td>\n",
       "      <td>175.762646</td>\n",
       "      <td>33155.578218</td>\n",
       "      <td>7.350233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.044783</td>\n",
       "      <td>11.039070</td>\n",
       "      <td>69.845400</td>\n",
       "      <td>3.298875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>5.126763</td>\n",
       "      <td>230.603758</td>\n",
       "      <td>11983.869376</td>\n",
       "      <td>6.303357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402.883113</td>\n",
       "      <td>11.168946</td>\n",
       "      <td>77.488213</td>\n",
       "      <td>4.708658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>7.874671</td>\n",
       "      <td>195.102299</td>\n",
       "      <td>17404.177061</td>\n",
       "      <td>7.509306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327.459760</td>\n",
       "      <td>16.140368</td>\n",
       "      <td>78.698446</td>\n",
       "      <td>2.309149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
       "0          NaN  204.890455  20791.318981     7.300212  368.516441   \n",
       "1     3.716080  129.422921  18630.057858     6.635246         NaN   \n",
       "2     8.099124  224.236259  19909.541732     9.275884         NaN   \n",
       "3     8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
       "4     9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
       "...        ...         ...           ...          ...         ...   \n",
       "3271  4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
       "3272  7.808856  193.553212  17329.802160     8.061362         NaN   \n",
       "3273  9.419510  175.762646  33155.578218     7.350233         NaN   \n",
       "3274  5.126763  230.603758  11983.869376     6.303357         NaN   \n",
       "3275  7.874671  195.102299  17404.177061     7.509306         NaN   \n",
       "\n",
       "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       564.308654       10.379783        86.990970   2.963135           0  \n",
       "1       592.885359       15.180013        56.329076   4.500656           0  \n",
       "2       418.606213       16.868637        66.420093   3.055934           0  \n",
       "3       363.266516       18.436524       100.341674   4.628771           0  \n",
       "4       398.410813       11.558279        31.997993   4.075075           0  \n",
       "...            ...             ...              ...        ...         ...  \n",
       "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
       "3272    392.449580       19.903225              NaN   2.798243           1  \n",
       "3273    432.044783       11.039070        69.845400   3.298875           1  \n",
       "3274    402.883113       11.168946        77.488213   4.708658           1  \n",
       "3275    327.459760       16.140368        78.698446   2.309149           1  \n",
       "\n",
       "[3276 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_data = pd.read_csv('data/water_potability.zip')\n",
    "water_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой признак — Potability (пригодность для питья): 1 — вода пригодна, 0 — вода не пригодна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE = 'Potability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ph               2785 non-null   float64\n",
      " 1   Hardness         3276 non-null   float64\n",
      " 2   Solids           3276 non-null   float64\n",
      " 3   Chloramines      3276 non-null   float64\n",
      " 4   Sulfate          2495 non-null   float64\n",
      " 5   Conductivity     3276 non-null   float64\n",
      " 6   Organic_carbon   3276 non-null   float64\n",
      " 7   Trihalomethanes  3114 non-null   float64\n",
      " 8   Turbidity        3276 non-null   float64\n",
      " 9   Potability       3276 non-null   int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 256.1 KB\n"
     ]
    }
   ],
   "source": [
    "water_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных есть пропуски. Выведем информацию о них в процентном соотношении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 14.99\n",
       "Hardness            0.00\n",
       "Solids              0.00\n",
       "Chloramines         0.00\n",
       "Sulfate            23.84\n",
       "Conductivity        0.00\n",
       "Organic_carbon      0.00\n",
       "Trihalomethanes     4.95\n",
       "Turbidity           0.00\n",
       "Potability          0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colums_with_null = (water_data.isnull().mean() * 100).round(2)\n",
    "colums_with_null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получу список признаков в которых есть пропуски "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ph', 'Sulfate', 'Trihalomethanes']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_columns = list(colums_with_null[colums_with_null > 0].index)\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас отсутствует \n",
    "\n",
    "около 15 % информации о кислотности воды (ph), \n",
    "\n",
    "около 24 % — о содержании сульфатов (Sulfate) \n",
    "\n",
    "около 5 % — о тригалометанах (Trihalomethanes). \n",
    "\n",
    "Мы знаем, что пропуски — непосильная ноша для большинства моделей машинного обучения. Их необходимо обработать.\n",
    "\n",
    "Заполним пропуски медианным значением в признаке зависимости класса воды (Potability). \n",
    "\n",
    "Для этого сгруппируем данные по признаку Potability, посчитаем медиану в каждой группе, а затем отправим результат в метод fillna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В цикле заполняю пропуски медианным значением в разрезе целевого признака\n",
    "for col in null_columns:\n",
    "    # Заполняем пропуски\n",
    "    water_data[col] = water_data[col].fillna(water_data.groupby(TARGET_FEATURE)[col].transform('median'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проблема пропусков устранена. \n",
    "\n",
    "Давайте по традиции разделим набор данных на матрицу наблюдений X и вектор правильных ответов y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = water_data.drop(TARGET_FEATURE, axis=1)\n",
    "y = water_data[TARGET_FEATURE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы используем двухкомпонентный подход (разбиваем выборку на тренировочную и валидационную, она же тестовая), то всё очень просто: нам лишь нужно вызвать функцию train_test_split() и передать в неё матрицу наблюдений X и вектор-столбец с правильными ответами y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (656, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели будем использовать дерево решений с максимальной глубиной 7, энтропией в качестве критерия информативности, минимальное число объектов в листе дерева — 5.\n",
    "\n",
    "После обучения сделаем предсказание для каждой из выборок и рассчитаем метрику. В качестве метрики для простоты возьмём долю правильных ответов — accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hold-out accuracy: 0.82\n",
      "Valid hold-out accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', # критерий информативности\n",
    "    max_depth=7, # максимальная глубина\n",
    "    min_samples_leaf=5, # минимальное число объектов в листе\n",
    "    random_state=42 # генератор случайных чисел  \n",
    ")\n",
    "\n",
    "# Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "# Выводим значения метрик\n",
    "print(f'Train hold-out accuracy: {metrics.accuracy_score(y_train, y_train_pred):.2f}')\n",
    "print(f'Valid hold-out accuracy: {metrics.accuracy_score(y_valid, y_valid_pred):.2f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же мы используем трёхкомпонентный подход (разбиваем выборку на тренировочную, валидационную и отдельную тестовую), тут нам понадобится чуть больше кода. К сожалению, в sklearn нет специализированного функционала для такого разбиения.\n",
    "\n",
    "Применим функцию train_test_split() дважды: сначала разобьём исходный набор на тренировочный и валидационный в соотношении 80/20, затем разобьём валидационный набор на валидационный и тестовый в соотношении 50/50. В итоге наша выборка будет разбита в соотношении 80/10/10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем исходную выборку на тренировочную и валидационную в соотношении 80/20\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = model_selection.train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (328, 9)\n",
      "Test shape: (328, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод k-fold более известен как кросс-валидация (cross validation), или перекрёстный контроль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', # критерий информативности\n",
    "    max_depth=7, # максимальная глубина\n",
    "    min_samples_leaf=5, # минимальное число объектов в листе\n",
    "    random_state=42 # генератор случайных чисел  \n",
    ")\n",
    " \n",
    "# Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Создаём список для хранения тренировочных и валидационных метрик\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "\n",
    "# Организуем цикл для кросс-валидации (используем весь набор данных)\n",
    "# train_index — индексы тренировочной выборки\n",
    "# valid_index — индексы валидационной выборки\n",
    "for train_index, valid_index in kf.split(X, y):\n",
    "    # Создаём тренировочную и валидационную выборку, обращаясь по текущим индексам\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    \n",
    "    # Обучаем случайный лес на тренировочной выборке\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Делаем предсказание для каждой из выборок\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Рассчитываем метрику и заносим её в список\n",
    "    train_metrics.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    val_metrics.append(metrics.accuracy_score(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8213740458015267, 0.8168637924456315, 0.8096146508966043, 0.8057993132392217, 0.8031285768790538]\n",
      "[0.7713414634146342, 0.7984732824427481, 0.76793893129771, 0.7282442748091603, 0.766412213740458]\n"
     ]
    }
   ],
   "source": [
    "print(train_metrics)\n",
    "print(val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для агрегированной оценки рассчитаем среднее значение метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "print(f'Train k-fold mean accuracy: {np.mean(train_metrics):.2f}')\n",
    "print(f'Valid k-fold mean accuracy: {np.mean(val_metrics):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### На самом весь приведённый выше код можно значительно сократить,\n",
    "### если использовать специальную функцию для кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02500463, 0.02100444, 0.02000189, 0.02200389, 0.02200556,\n",
       "        0.02100515, 0.02100348, 0.0220046 , 0.02100754, 0.02201796]),\n",
       " 'score_time': array([0.00200367, 0.00100183, 0.00200319, 0.0010004 , 0.00100017,\n",
       "        0.00099874, 0.00099635, 0.00100017, 0.00100541, 0.00099993]),\n",
       " 'test_score': array([0.7804878 , 0.75304878, 0.73780488, 0.72256098, 0.7804878 ,\n",
       "        0.76829268, 0.74923547, 0.76146789, 0.77370031, 0.76146789]),\n",
       " 'train_score': array([0.80257802, 0.81648575, 0.82157395, 0.80122117, 0.79918589,\n",
       "        0.80936228, 0.80196677, 0.7965412 , 0.7972194 , 0.8138352 ])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', # критерий информативности\n",
    "    max_depth=7, # максимальная глубина\n",
    "    min_samples_leaf=5, # минимальное число объектов в листе\n",
    "    random_state=42 # генератор случайных чисел  \n",
    ")\n",
    " \n",
    "# Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=42)\n",
    " \n",
    "# Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, # модель\n",
    "    X=X, # матрица наблюдений X\n",
    "    y=y, # вектор ответов y\n",
    "    cv=kf, # кросс-валидатор\n",
    "    scoring='accuracy', # метрика\n",
    "    return_train_score=True # подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "\n",
    "cv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train = np.mean(cv_metrics['train_score'])\n",
    "mean_test = np.mean(cv_metrics['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Test k-fold mean accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(f'Train k-fold mean accuracy: {mean_train:.2f}')\n",
    "print(f'Test k-fold mean accuracy: {mean_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили тот же результат, что и ранее. Согласитесь, функция cross_validate() значительно облегчает работу с кросс-валидацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEAVE-ONE-OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод leave-one-out (отложенный пример), или поэлементная кросс-валидация — это частный случай кросс-валидации (k-fold), когда размер  равняется размеру всей выборки , где  — количество примеров (строк в таблице)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики будет рассчитано не для всего набора данных, а только для его части. Если вы захотите рассчитать метрику на всём наборе данных, вместо среза передавайте в функцию таблицу X и столбец y целиком. Но имейте в виду, что код в таком случае может выполняться до нескольких минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', # критерий информативности\n",
    "    max_depth=7, # максимальная глубина\n",
    "    min_samples_leaf=5, # минимальное число объектов в листе\n",
    "    random_state=42 # генератор случайных чисел  \n",
    ")\n",
    " \n",
    "# Создаём кросс-валидатор LeaveOneOut\n",
    "loo = model_selection.LeaveOneOut()\n",
    " \n",
    "# Считаем метрики на кросс-валидации leave-one-out\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, # модель\n",
    "    X=X.iloc[:5000], # матрица наблюдений X\n",
    "    y=y.iloc[:5000], # вектор ответов y\n",
    "    cv=loo, # кросс-валидатор\n",
    "    scoring='accuracy', # метрика\n",
    "    return_train_score=True # подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce0e7e8478f0adf4f893607b28490b56060cc6330e9a48291a15f517e7031888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
